<script>
	import ProjectLinkButton from '$lib/components/ProjectLinkButton.svelte';
	import Img from '@zerodevx/svelte-img';
	import distractedBoyfriendMeme from "$lib/images/distractedboyfriendmeme.jpg?as=run";
	import mainDashboardScreenshot from "$lib/images/main-dashboard-screenshot.png?as=run";
	import chargeListingScreenshot from "$lib/images/charge-listing-screenshot.png?as=run";

	const { data } = $props();

	const projectUrl = "https://github.com/nickbrett1/ftn";
</script>

<style>
	.mermaid-container {
		display: flex;
		justify-content: center;
	}
</style>

<h1 class="!mb-0 no-underline">Building with AI Agents: 10 Thoughts from a 14,500-Line Project</h1>
<p class="text-xl text-gray-300 !mt-2 !mb-6">What I learned using Cursor's agent mode to build a personal finance tool</p>
October 2025
<ProjectLinkButton href={projectUrl} />

## Introduction

Over the past year, my relationship with AI coding assistants has evolved dramatically. What started as flirtations through simple tab completions with GitHub Copilot has transformed into something more like a marriage where I'm comfortable with AI agents handling entire components of my applications. I've been building software for more than 20 years, and so I wanted to draw out a few thoughts about the experience from a recent personal project that was built using [Cursor's agent mode](https://cursor.com/docs/agent/modes#agent).

<Img src={distractedBoyfriendMeme} alt="Meme illustrating the appealing opportunity to use AI Agents instead of manual coding" class="mx-auto my-4 max-w-md" />

To give a sense of the scale of the work, this project had the goal of developing a system to automate a piece of my own finance management by removing the tedious process of reviewing monthly credit card statements (yes I do this). The system parses PDF statements from various credit card providers, extracts charges, and helps categorize spending into budgets.

**Project Scale:** The final codebase spans approximately **14,500 lines of code**, with **72% JavaScript/TypeScript** and **28% Svelte components**.

## Code Distribution by System Area

There are five main areas to the code:

**Frontend (60% at ~8,700 lines):** 63 Svelte components handling the user interface, from billing cycle dashboards to PDF upload interfaces.

**Backend APIs (35% at ~5,100 lines):** 37 JavaScript files powering SvelteKit server routes, business logic, and API orchestration between parsing, database, and external services.

**Data Processing (4% at ~600 lines):** PDF statement parsers for different formats, plus logic to normalize merchant names.

**Database Layer (1% at ~100 lines):** Cloudflare D1 (SQLite) and R2 storage integration, migrations, and query optimization for persistent data operations.

## Screenshots

<div class="grid grid-cols-1 md:grid-cols-2 gap-6 my-6">
	<div class="text-center">
		<Img src={mainDashboardScreenshot} alt="Main dashboard showing billing cycles and budgets" class="mx-auto rounded-lg shadow-lg max-w-full h-auto" />
		<p class="text-sm text-gray-400 mt-2">Main dashboard showing different billing cycles; each contains statements for multiple credit cards</p>
	</div>
	<div class="text-center">
		<Img src={chargeListingScreenshot} alt="Statement parsing interface with charge allocation" class="mx-auto rounded-lg shadow-lg max-w-full h-auto" />
		<p class="text-sm text-gray-400 mt-2">Charge listing view, where charges across multiple cards can be viewed and assigned to budgets</p>
	</div>
</div>

## The Evolution of My AI Agent Use

My journey with AI coding assistants has, like many others, gone something like this:

1. **Tab Completions (Late 2024):** I started using GitHub Copilot with basic tab completions and simple function suggestions
2. **Entire Scripts and fFiles (Early 2025):** After 3-6 months I was using Google Gemini to help write entire scripts and files for my [dbt-duckdb project](https://github.com/nickbrett1/ftn/tree/main/webapp/src/routes/projects/dbt-duckdb)
3. **Agent Mode (Mid 2025):** More recently, with this project, I embraced 'the vibe' and started to use Cursor's agent mode for component development

This evolution follows a fundamental shift from AI as a coding assistant to AI as a collaborative development partner. For the ccbilling project, I specifically leveraged Cursor's 'Auto' model, which intelligently selects the best underlying AI model for any given query - whether that's Claude Sonnet for complex reasoning or GPT-4 for code generation. Here's what I've learned.

## 10 Key Lessons Learned

### 1. Planning Upfront Works Well

> **Key Insight:** The clearer you define the initial requirements and architecture, the more effective AI agents can be.

The most successful AI agent interactions started with clear structure and requirements. I began the ccbilling project with a comprehensive [requirements document](https://github.com/nickbrett1/ftn/blob/main/docs/ccbilling.md) that outlined the data model, user flows, and technical constraints. This gave the agent a solid foundation to work from.

I also asked the agent to create a [comprehensive TODO file](https://github.com/nickbrett1/ftn/blob/main/.cursor/ccbilling-todo.md) that tracked progress and provided clear next steps. I think this approach is becoming highly standardized, with tools like [Amazon's new IDE Kiro](https://kiro.dev/) designed around it.

Whenever I didn't do this, or tried to cut corners, I found the agent getting lost or producing poor quality output that took a long time to iterate on to get to an acceptable place.

### 2. Automated Checks Are More Valuable

> **Key Insight:** Automation isn't just about speed - it's about providing AI agents with structured, actionable feedback they can use.

With AI agents generating significant portions of code, automated quality checks become essential rather than optional. I leveraged [SonarCloud](https://sonarcloud.io/summary/new_code?id=nickbrett1_bem) for comprehensive code quality analysis, which helped the AI agent act more autonomously by preventing deployments even getting to human review unless they had passed the automated checks.

To do this, I used a CI/CD pipeline on [CircleCI](https://github.com/nickbrett1/ftn/blob/main/.circleci/config.yml) that enforced test coverage and quality standards, providing structured feedback that the agent could use to address problems. This created a virtuous cycle where the agent would generate code, tests would identify issues, and the agent would fix them based on the structured error output.

### 3. Coding on Just a Phone Is Doable

> **Key Insight:** The future of development isn't tied to a specific device or location - AI agents enable code anywhere workflows.

One of the most surprising discoveries was Cursor's agent mode webapp, which allowed me to operate the AI agent outside of the IDE through a web interface. The agent spins up a VM to make changes to a branch, enabling development from anywhere.

This capability fundamentally changed my development workflow. It suddenly meant I could do real coding from anywhere - which is both empowering and potentially dangerous for work-life balance. But for personal projects like ccbilling, it's been a massive boost.

### 4. Environment Iteration Becomes Critical

> **Key Insight:** When AI agents can work autonomously, you need systems that let you observe and iterate on their work safely.

Given the ability to code from anywhere, having an environment that supports rapid iteration became really important. While this is straightforward on desktop, where I can just run my app locally with any changes. When I was working just using the Cursor webapp, I needed to invest in creating [preview deployments for branches](https://github.com/nickbrett1/ftn/tree/main/webapp/src/routes/deploys), accessible through a special `/deploys` route.

This preview system allowed me to see what the agent was building when I was just interacting with it through my phone, without risking my main site by having it commit to the main branch. The investment in infrastructure to create a safe space for experimentation and iteration paid dividends in development velocity.

### 5. UI Changes Remained Difficult

> **Key Insight:** AI agents excel at logic and structure but struggle with subjective visual decisions. Clear design systems and component libraries help.

Despite AI agents' capabilities, UI changes proved challenging. Describing placement and styling in natural language is inherently imprecise, and without a consistent design language, the agent struggled with visual consistency.

I addressed this by introducing a standardized [Button component](https://github.com/nickbrett1/ftn/blob/main/webapp/src/lib/components/Button.svelte) with clear style variants and documenting my [style guidelines in the context file](https://github.com/nickbrett1/ftn/blob/main/.cursor/context.md). The more structured and consistent I made my UI components, the easier it is for agents to work with them.

### 6. There Were Bugs to Work Around

> **Key Insight:** AI agents introduce new failure modes that require creative workarounds and clear documentation.

AI agents aren't perfect, and I encountered several technical issues that required workarounds. For example, my use of zsh with powerlevel10k caused Cursor to hang when running terminal commands. I solved this by adding conditional logic to my [.zshrc configuration](https://github.com/nickbrett1/ftn/blob/main/.devcontainer/.zshrc):

<!-- svelte-ignore a11y_no_noninteractive_tabindex -->

```bash
# Set Oh My Zsh theme conditionally to avoid Cursor hanging issues
if [[ "$PAGER" == "sh -c \"head -n 10000 | cat\"" ]]; then
  ZSH_THEME=""  # Disable Powerlevel10k for Cursor chat terminals only
else
  ZSH_THEME="powerlevel10k/powerlevel10k"
fi
```

Similarly, Cursor would hang when running tests from my desktop, so I needed to introduce a special command (`npm run test:once`) for it to use to run tests, which again needed to be documented in my context file to guide the agent.

### 7. Newer Frameworks Are Challenging

> **Key Insight:** AI agents work best with established patterns and examples. For cutting-edge technologies, you need to create your own reference implementations.

The agent struggled significantly with Svelte 5's runes mode and its approach to UI reactivity. This relatively new version of the framework, released in October 2024, meant there was less training data for the agent, making it harder to generate correct code.

A concrete example of this was when the agent tried to implement reactive state using Svelte 5's `$state` rune. The agent would often make the mistake of directly assigning to a `$state` variable, which breaks reactivity:

<!-- svelte-ignore a11y_no_noninteractive_tabindex -->

```javascript
// ❌ What the agent would generate (incorrect)
let count = $state(0);

function increment() {
	count = count + 1; // This assignment breaks reactivity!
}

// ✅ Correct approach with $state
let count = $state(0);

function increment() {
	count++; // Direct mutation maintains reactivity
}
```

The agent's confusion stemmed from its training on older Svelte patterns where you would reassign variables. With runes, the reactive system expects direct mutation rather than reassignment, which is a subtle but critical difference that the agent initially missed.

However, once I had a body of examples in my own codebase that the agent could reference and copy from, its performance improved dramatically. As a result I learned that sometimes creating internal examples and patterns was crucial when working with newer APIs.

### 8. More Software Will Be Written

> **Key Insight:** AI agents don't replace programmers - they enable more people to create more software to solve more problems.

There's an ongoing debate about what AI agents mean for the programming profession. I'm relatively optimistic: I believe this will make it much easier to create new software, but that there's so much demand for software that we'll see significantly more of it written.

The ccbilling tool is a perfect example - it's a useful personal finance application that I would never have built without AI assistance. The barrier to entry for creating software has been dramatically lowered, which means more people can solve more problems.

### 9. Quality Can Actually Improve

> **Key Insight:** AI agents can raise software quality by implementing best practices and enabling architectural experimentation that would be too time-consuming otherwise.

A common concern is that AI-generated code will lower software quality. In my experience, when used well, the opposite can be true. I was able to use agents to implement many quality-enhancing systems that I wouldn't have had time to build otherwise.

For example, the preview deployment system, comprehensive test coverage, and automated quality checks all contribute to higher software quality. The agent also enabled me to quickly try different approaches to solving problems, allowing me to choose the best solution rather than being stuck with the first working implementation.

### 10. Surprisingly Fun

> **Key Insight:** AI agents can make development more collaborative and engaging, not less human.

Perhaps most unexpectedly, working with AI agents was at times genuinely enjoyable. The back-and-forth on approaches mimicked the collaborative feeling of working with other developers. While agents can be somewhat fawning in their responses, there's something genuinely satisfying about having a conversation about code architecture and then watching it come to life.

## The Trade-off: Knowledge vs. Velocity

As exciting as this new approach is, I do feel like something is lost by not knowing every detail of the codebase as thoroughly as when I'd written it all myself. There's a certain confidence that comes from having written every line, and some debugging scenarios become more challenging when you're not intimately familiar with the implementation details.

However, I believe this trade-off is inevitable and that the positives outweigh the negatives. The ability to build more ambitious projects, implement better architectures, and focus on higher-level problem-solving compensates for the loss of deep implementation knowledge.

## Looking Forward

As AI agents continue to evolve, I'm excited to see how they'll further transform software development. The key right now I believe is not to treat them as replacements for human developers, but as collaborative partners that can amplify our capabilities and enable us to build better software, faster.

For those interested in exploring this approach, I'd recommend starting with a well-defined, self-contained project. The combination of clear requirements, automated testing, and AI assistance can create a powerful development environment.
