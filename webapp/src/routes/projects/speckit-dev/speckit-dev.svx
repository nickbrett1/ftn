<script>
	import ProjectLinkButton from '$lib/components/ProjectLinkButton.svelte';
	import SpendChart from '$lib/components/SpendChart.svelte';
	import Img from '@zerodevx/svelte-img';
	import speckitMeme from '$lib/images/speckit-meme.jpg?as=run';
	import genprojDecomposable from '$lib/images/genproj-decomposable.jpeg?as=run';

	const { data } = $props();

	const projectUrl = "https://github.com/nickbrett1/ftn";
</script>

<style>
	.mermaid-container {
		display: flex;
		justify-content: center;
		white-space: pre-wrap;
		overflow-x: auto;
	}
</style>

<h1 class="!mb-0 no-underline">Vibe Coding with Spec Kit</h1>
<p class="text-xl text-gray-300 !mt-2 !mb-6">Structured approaches for building with agents</p>
December 2025
<ProjectLinkButton href={projectUrl} />

## Introduction

[Spec Kit](https://github.com/github/spec-kit) is a framework that helps define specifications for projects that are then built with agents. Or perhaps more simply stated, it provides a structured approach for "vibe coding".

I wanted to try Spec Kit after my [past experience with agents](/projects/building-with-ai) to see if I could do better. Spec Kit helps define the requirements for a project, along with the necessary constraints that need to be upheld, aiming to make development with agents more productive and produce higher quality results.

<p class="mb-4">How did it go?</p>
<figure class="my-8 mx-auto max-w-md">
    <Img src={speckitMeme} alt="Drake Hotline Bling Meme about using SpecKit" class="rounded-lg shadow-lg w-full" />
    <figcaption class="text-center text-sm text-gray-500 mt-2 italic">
        Although this captures my sentiment at times using Spec Kit, there was lots of promise and I could see it working better with practice and more support for iterative development.
    </figcaption>
</figure>

Well overall I struggled to utilize Spec Kit well, but did learn many valuable lessons along the way.

## Selecting a Project

To put Spec Kit to the test, I chose to build [Genproj](/projects/genproj). Genproj is a code generator that creates the boilerplate configuration for a selection of tools that I find valuable to make it easy to get going with new projects. I feel I get a lot of benefit from things like [containers for my development workflow](https://code.visualstudio.com/docs/devcontainers/containers), [CI/CD setup](https://circleci.com/), [secrets management](https://www.doppler.com/), and of course nowadays [setting up agents](https://ai.google.dev/gemini-api/docs/quickstart) but they can be time consuming to setup.
Using an agent for this project seemed like a good match because:

1.  **Open APIs:** All the tools I wanted to integrate had open APIs with online documentation, such as the [GitHub Oauth API](https://docs.github.com/en/apps/oauth-apps/building-oauth-apps/authorizing-oauth-apps) and the [vscode devcontainer configuration](https://containers.dev/implementors/json_reference/). Understanding how to integrate with them isn't technically difficult, but it is time-consuming, so an agent should do this well.
2.  **Decomposable:** The project could easily be decomposed. Every tool has a UI element, maybe some configuration for how it should be used, and then generates some code. Nice and repeatable for an agent.

    <figure class="my-4 mx-auto max-w-lg">
        <Img src={genprojDecomposable} alt="GenProj capability cards" class="rounded-lg shadow-lg w-full" />
        <figcaption class="text-center text-sm text-gray-500 mt-2 italic">
            Note the auto-configuration for these three capabilities, showing their similarity.
        </figcaption>
    </figure>
3.  **Clear Spec:** The spec felt pretty easy to define; there wasn't much UI or obvious ambiguity.
4.  **Right Size:** It was a project that wasn't so small I could do it in a few prompts, but didn't seem so large that it would take a lot of effort to specify.

## How to use Spec Kit

Let me first explain how I used Spec Kit in the context of the artifacts that need to be created.

### The Constitution

[.specify/memory/constitution.md](https://github.com/nickbrett1/ftn/blob/main/.specify/memory/constitution.md) - This file defined all the principles that I didn't want the agents violating when creating the project. Things like code quality and testing.

Creating this was quite good fun; it made me think about how I developed software, and I like the name 'constitution' as a way to enforce certain non-negotiables. 

A lot of this effort could be repurposed as well into AGENTS.md for use outside of Spec Kit.

### The Specification

[specs/001-genproj/spec.md](https://github.com/nickbrett1/ftn/blob/main/specs/001-genproj/spec.md) - Next up was the specification for the project itself. I wrote the input section and then Spec Kit generated the user stories. There were more stories created than I anticipated, and perhaps were needed - which I think as we mention later in the article led to more work from the agent and more cost.

As always, having to actually write down the spec really helped me crystalize what I wanted.

### The Tasks

From there, it was over to Spec Kit to generate a task breakdown to build Genproj: [specs/001-genproj/tasks.md](https://github.com/nickbrett1/ftn/blob/main/specs/001-genproj/tasks.md).

## Lessons Learned

### 1. Agents can be expensive!

With Spec Kit, agents are doing a lot of work. Of course, this additional work is geared towards a higher quality result, breaking down tasks and validating work against the constitution. But it came with, quite literally, a cost.

<SpendChart />

When I was using Spec Kit I could rapidly exhaust all my monthly ($20) Cursor credits in 2-3 hours including a ($10) top up. The sums weren't huge, but if I can be coding most nights, I could see this becoming many hundreds of dollars a month. Enough to give pause.

**Solution?** Could we try to use different agents, some cheaper and less capable, for different Spec Kit activities? Not everything needs the most advanced model, but it wasn't at all obvious how to do this.

### 2. Hard to iterate on specs

I had tried with this project to pick something manageable in scope and complexity, and I was hoping the structured approach from Spec Kit would help manage that as well.

But I still ran into problems. Primarily these were because I had missed out details in my specification. But because of that, I wanted to just update my specs and add/remove some stuff.

But the workflow in Spec Kit isnâ€™t really geared to this kind of iteration, and I found myself just deleting what had been produced and going back. This was a major reason costs exploded.

To better understand this, let's look at the standard Spec Kit workflow. It is designed as a linear progression of commands:

<div class="mermaid-container">

```mermaid
graph TD
    A["1. Init Project&#10&#36; specify init"] --> B["2. Establish Principles&#10/speckit.constitution"]
    B --> C["3. Create Spec&#10/speckit.specify"]
    C --> D["4. Create Tech Plan&#10/speckit.plan"]
    D --> E["5. Create Tasks&#10/speckit.tasks"]
    E --> F["6. Execute&#10/speckit.implement"]
    linkStyle 0,1,2,3,4 stroke:#d8b4fe,stroke-width:2px;
```

</div>

The problem is when you reach step 6 and have generated code and realize something is missing from step 3 because then you have generated a lot of work. There isn't an obvious way to simply "update" the spec and have the changes ripple through to the plan and tasks intelligently. Instead, the workflow encourages a forward-only motion. To iterate, I often found myself manually deleting generated files and re-running the commands from the earlier steps, regenerating everything in between. This repetition is what drove up the costs.

**Solution?** Helping coding agents work, and be aware of, iterative workflows seems key. It's a hard state management problem, as it is for humans, but we'll need better approaches for this.

### 3. Big changes are difficult to manage

Even when I could get a large change that I was happy with, I would face the normal problems of how to merge that back into my main branch.

All Spec Kit changes for a given project go into a single branch, and when you kickoff the implementation it powers forward. To highlight quite how much work Spec Kit generated for this relatively simple project, here is the breakdown of the generated tasks:

| Phase Type | Count |
| :--- | :--- |
| Setup & Foundation | 2 phases (12 tasks) |
| User Stories | 9 phases (80 tasks) |
| Polish & Error Handling | 2 phases (15 tasks) |
| **Total** | **13 phases (107 tasks)** |

This led to a huge amount of code being generated in a single go, maybe not all I wanted, and increased the chances of conflicts with the main branch. I think the key point is that Spec Kit took a relatively maximalist approach to interpreting the specifications, with a lot of capability.

**Solution?** A human doing this work would have more understanding as to when to pause, when maybe to split the work across multiple branches, when to suggest merging pieces back into main. It seems we'll need more tooling for LLMs to do the same.

### 4. Conclusion

The conclusion was that Spec Kit enables LLMs to take on much larger pieces of work more autonomously - and uses strong guardrails to ensure correctness. Through my own use of the tool, I still found the guardrails insufficient, though I also could have selected a project that was too complex to do in one shot or not sufficiently specified my needs.

I ended up taking some of the Spec Kit code and then just iterating on it directly with my agent to complete the project.

## Other Thoughts on Agent Tools

A few other thoughts and lessons on agent tools from building this project:

### New AI Agent IDEs

In this project, I tried some of the new AI Agent IDEs, such as the [Antigravity IDE from Google](https://antigravity.google/). I wanted to see if, in a similar way to Spec Kit, these tools could help me work at a higher level of abstraction by providing more structure for using LLMs.

**What happened?** I found that it suffered from the same cost problem. I ran out of credits within 15 minutes and so couldn't really evaluate it. Note, Google has since increased the free tier usage amounts but I haven't revisited.

### Gemini - No Strict Limits

After exhausting my Cursor credits, I tried [Gemini](https://github.com/google-gemini/gemini-cli) and this had the nice property that instead of cutting me off entirely from a model when I ran out of credits, it would just degrade me to an earlier model version for a few hours.

For my personal projects, where I might be doing a couple of hours work at a time, this worked really well. I haven't looked back.

### Coding from my phone: Jules > Cursor

With my switch away from Cursor, I lost access to [Cursor's Cloud Agents](https://cursor.com/blog/cloud-agents). Per my [previous article](/projects/building-with-ai), these were really useful to help me make small incremental feature updates and bug fixes when away from my desktop.

I've switched over to [Jules](https://jules.google.com/), the Google equivalent, and found it to be better. Cursor cloud agents regularly got stuck while this happens less frequently with Jules.

Its web interface uses so much client-side memory it can fail to load on my phone if a chat thread is too long. But if I keep my requests small and incremental it seems to work well, and does have some recent new features that seem cool, such as suggestions (though I haven't seen many to know how good they can be).

### MCP Integration is a Must

In my last agent project, I didn't invest time in setting up MCP integrations, or those integrations I would have liked didn't exist. This caused me challenges when working for example with [Svelte 5 code](https://fintechnick.com/projects/building-with-ai#7-newer-frameworks-are-challenging).

For this project, I took the time to set up three MCP integrations:

1.  **Svelte:** [Svelte MCP](https://svelte.dev/docs/mcp/overview) made it easier to make UI changes correctly.
2.  **SonarQube:** [SonarQube MCP](https://github.com/SonarSource/sonarqube-mcp-server) made it trivial to correct all my SonarQube violations.
3.  **Chrome DevTools:** [Chrome DevTools MCP](https://github.com/ChromeDevTools/chrome-devtools-mcp) that I haven't used as much but when I've hit difficult CSS-based problems is very useful for the agent to 'see' the browser output.

Overall these seemed to be at least as valuable as upgrading my model from Gemini 2 to Gemini 3, and I expect more gains from thinking about how to provide agents with access to more tools.

## What's Next?

Well Spec Kit didn't quite pan out for me, but I did use the project to upgrade many aspects of my workflow. So what's next? I'm thinking about two possibilities:

1.  **Local Models:** Model expense was clearly a challenge. I'm left wondering whether an LLM running locally could help here, at least for some tasks. I have a 2-year old MacStudio with a good amount of RAM so this might be an interesting path, especially if I can tune a model for my workflows.
2.  **Hardware Project:** I want to push the boat out and see if an agent can help me with a hardware project, something that would be pretty daunting to attempt otherwise. Stay tuned!
