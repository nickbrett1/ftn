I'd like to create an article with a similar style (both the style of writing and the layout, fonts, styling etc..) to that in webapp/src/routes/dbt-duckdb/dbt-duckdb.svx that will discuss what I've learned by building with AI agents through the work on the ccbilling project on this site. It would be nice if it could have a nice gimmick or meme to hook people in with an image - like we had for dbt-duckdb.svx.

I want you to create a first draft of this article under webapp/src/projects/ccbilling/building-with-ai.svx

Here's the structure that I propose we follow along with notes for each section to use:

- Introduction. Introduce the article and provide context on the ccbilling project, what it is intended to achieve. For this, please refer to the code under ccbilling as well as the initial ccbilling.md file in docs that gives an overview. I want to highlight the number of lines of code in the project, which is about 14500, 72% JavaScript and 28% Svelte. Please use mermaid to generate an architecture diagram to explain the key components of the project, and leave placeholders for a couple of screenshots that I can add. Highlight that as a personal self-contained project, it appeared to be a good candidate for using an AI agent.

- AI Agent Use. Show that over the past year, my use of AI agents has evolved, from using GitHub copilot for tab completions, through in my last project (link to dbt-duckdb article) where I used Gemini for writing some scripts and larger files, to this project where I adopted Cursor and used their agent mode for significant components of the site. For those interested, highlight that I specifically used Cursor's 'Auto' model which selects the best underlying model for any given query. Give a mermaid diagram again highlighting this evolution in my use, from simple tab assist through to leveraging AI agents for entire components.

- For the main content in the article, I'd like to structure it as 10 things I learned to make it easily digestible and visually easy to navigate. These ten points will be:

1. Planning upfront works well - link to the MD doc for the ccbillign project giving initial requirements and explain that the agent worked well when given a structure to start from. Also asked the agent to create a TODO file (link to it in .cursor/ccbilling-todo.md) Highlight that this pattern is something that Amazon's new IDE Kiro (@https://kiro.dev/ ) is structured - though a footnote is that I'm still on the waitlist to try it.

2. Automated checks are more valuable. Highlight my use of sonarqube in the project (link to quality report: @https://sonarcloud.io/summary/new_code?id=nickbrett1_bem) and how having automation to enforce test coverage and code quality is even more valuable with agents as another way to ensure you're getting quality output as they can catch many problems far more quickly than human code review and provide structure output that the agent can use to address the problems. I was fortunate that my app already had an automated CI/CD build process on CircleCI (link to configuration in project) to make these checks easy to leverage.

3. Coding on just a phone is doable. Explain Cursor's agent mode that can operate through a webapp outside of the IDE and will spin up a VM to make changes to a branch. Highlight how amazing it was to be able to make changes when away from my Desktop setup and although like the introduction of the mobile phone, it now means I can code from anywhere and so risking that work can be even more pervasive, it's still a big productivity booster, especially on personal projects.

4. Given point 3, it becomes even more important to have an environment that allows for iteration. This is easy on the Desktop, but when using the Agent mode on a phone, I found I needed to invest to create a preview deployment for all branches of my project (link to /deploys route). This made it possible to see what the agent was doing without risking breaking my main site.

5. UI changes remained difficult. It's not easy to describe placement and styling in English, and I wasn't using a design language, common components or had any style guidelines. I introduced a Button component (link to file in llb/components) with some clear style options and outlined my style guidelines in my .cursor/context.md file (link to file). The clearer and more consistently structured you can make UI, the easier it is for agents to work with.

6. There were bugs to workaround. For example my use of zsh and powerlevel10k (provide link) caused Cursor to hang when running commands. Adding some extra checks to detect this and disable my shell formatting solved it (inline the appropriate section of the .zshrc here as code to demonstrate). Also Cursor would hang when running tests in watch mode, I had to introduce a special npm run test:once command that would avoid this and then add instructions in my context.md to instruct Cursor on how to run tests.

7. The Agent worked much less well with newer frameworks. For example it got quite confused with Svelte5's runes mode (link to @https://svelte.dev/blog/runes ) and its approach to UI reactivity. I didn't have a lot of Svelte5 code, and it seemed to get much better once there was a body of examples in my own codebase that it could copy.

8. More software. There's a debate as to what this means for programmers more generally. I'm relatively optimistic because I think this will make it much easier to create new software, but that there's so much demand for software that so much more will be written. This little ccbilling tool is an example that would never have been built, and is useful to me.

9. A question has been raised about whether agents will lower the quality of software. In my case, I think if used well we could see the opposite. In this project, I was able to use agents to add many systems that raise quality that I wouldn't have had the time to do otherwise. The ability to deploy preview deployments. Or that I was able to quickly try different approaches to solving a problem to establish which was best rather than feeling more compelled that I had to go with the first one I got up and coding.

10. Surprisingly fun. By and large it was enjoyable to work with the agent. The back and forth on approaches mimicked some of the feelings of collaboration when working with others. Although agents can be somewhat fawning, it still brought a smile to my face when Cursor would proclaim my basic suggestion was 'A great idea!'

And then as a last closing point, highlight that it's an exciting new approach but I do feel like a little something is lost by losing touch with knowing all of the details for all of the code as thoroughly as when I'd written it all myself. I think this is a real problem, but I have a feeling that it's inevitable and the positives outweigh it.
